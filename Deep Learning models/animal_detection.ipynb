{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of tensorflow-object-detection-training-colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx",
        "colab_type": "text"
      },
      "source": [
        "# [How to train an object detection model easy for free](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) | DLology Blog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq",
        "colab_type": "text"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mKS_koiMKkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d40414d-54a6-431a-a56d-5bd0dcd865f7"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!rm /usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UxeMBQIbS9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1cb4f06-e94a-4408-f116-e882f4d9ed98"
      },
      "source": [
        "%%writefile /usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\n",
        "__author__ = 'tsungyi'\n",
        "#/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from . import mask as maskUtils\n",
        "import copy\n",
        "\n",
        "class COCOeval:\n",
        "    # Interface for evaluating detection on the Microsoft COCO dataset.\n",
        "    #\n",
        "    # The usage for CocoEval is as follows:\n",
        "    #  cocoGt=..., cocoDt=...       # load dataset and results\n",
        "    #  E = CocoEval(cocoGt,cocoDt); # initialize CocoEval object\n",
        "    #  E.params.recThrs = ...;      # set parameters as desired\n",
        "    #  E.evaluate();                # run per image evaluation\n",
        "    #  E.accumulate();              # accumulate per image results\n",
        "    #  E.summarize();               # display summary metrics of results\n",
        "    # For example usage see evalDemo.m and http://mscoco.org/.\n",
        "    #\n",
        "    # The evaluation parameters are as follows (defaults in brackets):\n",
        "    #  imgIds     - [all] N img ids to use for evaluation\n",
        "    #  catIds     - [all] K cat ids to use for evaluation\n",
        "    #  iouThrs    - [.5:.05:.95] T=10 IoU thresholds for evaluation\n",
        "    #  recThrs    - [0:.01:1] R=101 recall thresholds for evaluation\n",
        "    #  areaRng    - [...] A=4 object area ranges for evaluation\n",
        "    #  maxDets    - [1 10 100] M=3 thresholds on max detections per image\n",
        "    #  iouType    - ['segm'] set iouType to 'segm', 'bbox' or 'keypoints'\n",
        "    #  iouType replaced the now DEPRECATED useSegm parameter.\n",
        "    #  useCats    - [1] if true use category labels for evaluation\n",
        "    # Note: if useCats=0 category labels are ignored as in proposal scoring.\n",
        "    # Note: multiple areaRngs [Ax2] and maxDets [Mx1] can be specified.\n",
        "    #\n",
        "    # evaluate(): evaluates detections on every image and every category and\n",
        "    # concats the results into the \"evalImgs\" with fields:\n",
        "    #  dtIds      - [1xD] id for each of the D detections (dt)\n",
        "    #  gtIds      - [1xG] id for each of the G ground truths (gt)\n",
        "    #  dtMatches  - [TxD] matching gt id at each IoU or 0\n",
        "    #  gtMatches  - [TxG] matching dt id at each IoU or 0\n",
        "    #  dtScores   - [1xD] confidence of each dt\n",
        "    #  gtIgnore   - [1xG] ignore flag for each gt\n",
        "    #  dtIgnore   - [TxD] ignore flag for each dt at each IoU\n",
        "    #\n",
        "    # accumulate(): accumulates the per-image, per-category evaluation\n",
        "    # results in \"evalImgs\" into the dictionary \"eval\" with fields:\n",
        "    #  params     - parameters used for evaluation\n",
        "    #  date       - date evaluation was performed\n",
        "    #  counts     - [T,R,K,A,M] parameter dimensions (see above)\n",
        "    #  precision  - [TxRxKxAxM] precision for every evaluation setting\n",
        "    #  recall     - [TxKxAxM] max recall for every evaluation setting\n",
        "    # Note: precision and recall==-1 for settings with no gt objects.\n",
        "    #\n",
        "    # See also coco, mask, pycocoDemo, pycocoEvalDemo\n",
        "    #\n",
        "    # Microsoft COCO Toolbox.      version 2.0\n",
        "    # Data, paper, and tutorials available at:  http://mscoco.org/\n",
        "    # Code written by Piotr Dollar and Tsung-Yi Lin, 2015.\n",
        "    # Licensed under the Simplified BSD License [see coco/license.txt]\n",
        "    def __init__(self, cocoGt=None, cocoDt=None, iouType='segm'):\n",
        "        '''\n",
        "        Initialize CocoEval using coco APIs for gt and dt\n",
        "        :param cocoGt: coco object with ground truth annotations\n",
        "        :param cocoDt: coco object with detection results\n",
        "        :return: None\n",
        "        '''\n",
        "        if not iouType:\n",
        "            print('iouType not specified. use default iouType segm')\n",
        "        self.cocoGt   = cocoGt              # ground truth COCO API\n",
        "        self.cocoDt   = cocoDt              # detections COCO API\n",
        "        self.params   = {}                  # evaluation parameters\n",
        "        self.evalImgs = defaultdict(list)   # per-image per-category evaluation results [KxAxI] elements\n",
        "        self.eval     = {}                  # accumulated evaluation results\n",
        "        self._gts = defaultdict(list)       # gt for evaluation\n",
        "        self._dts = defaultdict(list)       # dt for evaluation\n",
        "        self.params = Params(iouType=iouType) # parameters\n",
        "        self._paramsEval = {}               # parameters for evaluation\n",
        "        self.stats = []                     # result summarization\n",
        "        self.ious = {}                      # ious between all gts and dts\n",
        "        if not cocoGt is None:\n",
        "            self.params.imgIds = sorted(cocoGt.getImgIds())\n",
        "            self.params.catIds = sorted(cocoGt.getCatIds())\n",
        "\n",
        "\n",
        "    def _prepare(self):\n",
        "        '''\n",
        "        Prepare ._gts and ._dts for evaluation based on params\n",
        "        :return: None\n",
        "        '''\n",
        "        def _toMask(anns, coco):\n",
        "            # modify ann['segmentation'] by reference\n",
        "            for ann in anns:\n",
        "                rle = coco.annToRLE(ann)\n",
        "                ann['segmentation'] = rle\n",
        "        p = self.params\n",
        "        if p.useCats:\n",
        "            gts=self.cocoGt.loadAnns(self.cocoGt.getAnnIds(imgIds=p.imgIds, catIds=p.catIds))\n",
        "            dts=self.cocoDt.loadAnns(self.cocoDt.getAnnIds(imgIds=p.imgIds, catIds=p.catIds))\n",
        "        else:\n",
        "            gts=self.cocoGt.loadAnns(self.cocoGt.getAnnIds(imgIds=p.imgIds))\n",
        "            dts=self.cocoDt.loadAnns(self.cocoDt.getAnnIds(imgIds=p.imgIds))\n",
        "\n",
        "        # convert ground truth to mask if iouType == 'segm'\n",
        "        if p.iouType == 'segm':\n",
        "            _toMask(gts, self.cocoGt)\n",
        "            _toMask(dts, self.cocoDt)\n",
        "        # set ignore flag\n",
        "        for gt in gts:\n",
        "            gt['ignore'] = gt['ignore'] if 'ignore' in gt else 0\n",
        "            gt['ignore'] = 'iscrowd' in gt and gt['iscrowd']\n",
        "            if p.iouType == 'keypoints':\n",
        "                gt['ignore'] = (gt['num_keypoints'] == 0) or gt['ignore']\n",
        "        self._gts = defaultdict(list)       # gt for evaluation\n",
        "        self._dts = defaultdict(list)       # dt for evaluation\n",
        "        for gt in gts:\n",
        "            self._gts[gt['image_id'], gt['category_id']].append(gt)\n",
        "        for dt in dts:\n",
        "            self._dts[dt['image_id'], dt['category_id']].append(dt)\n",
        "        self.evalImgs = defaultdict(list)   # per-image per-category evaluation results\n",
        "        self.eval     = {}                  # accumulated evaluation results\n",
        "\n",
        "    def evaluate(self):\n",
        "        '''\n",
        "        Run per image evaluation on given images and store results (a list of dict) in self.evalImgs\n",
        "        :return: None\n",
        "        '''\n",
        "        tic = time.time()\n",
        "        print('Running per image evaluation...')\n",
        "        p = self.params\n",
        "        # add backward compatibility if useSegm is specified in params\n",
        "        if not p.useSegm is None:\n",
        "            p.iouType = 'segm' if p.useSegm == 1 else 'bbox'\n",
        "            print('useSegm (deprecated) is not None. Running {} evaluation'.format(p.iouType))\n",
        "        print('Evaluate annotation type *{}*'.format(p.iouType))\n",
        "        p.imgIds = list(np.unique(p.imgIds))\n",
        "        if p.useCats:\n",
        "            p.catIds = list(np.unique(p.catIds))\n",
        "        p.maxDets = sorted(p.maxDets)\n",
        "        self.params=p\n",
        "\n",
        "        self._prepare()\n",
        "        # loop through images, area range, max detection number\n",
        "        catIds = p.catIds if p.useCats else [-1]\n",
        "\n",
        "        if p.iouType == 'segm' or p.iouType == 'bbox':\n",
        "            computeIoU = self.computeIoU\n",
        "        elif p.iouType == 'keypoints':\n",
        "            computeIoU = self.computeOks\n",
        "        self.ious = {(imgId, catId): computeIoU(imgId, catId) \\\n",
        "                        for imgId in p.imgIds\n",
        "                        for catId in catIds}\n",
        "\n",
        "        evaluateImg = self.evaluateImg\n",
        "        maxDet = p.maxDets[-1]\n",
        "        self.evalImgs = [evaluateImg(imgId, catId, areaRng, maxDet)\n",
        "                 for catId in catIds\n",
        "                 for areaRng in p.areaRng\n",
        "                 for imgId in p.imgIds\n",
        "             ]\n",
        "        self._paramsEval = copy.deepcopy(self.params)\n",
        "        toc = time.time()\n",
        "        print('DONE (t={:0.2f}s).'.format(toc-tic))\n",
        "\n",
        "    def computeIoU(self, imgId, catId):\n",
        "        p = self.params\n",
        "        if p.useCats:\n",
        "            gt = self._gts[imgId,catId]\n",
        "            dt = self._dts[imgId,catId]\n",
        "        else:\n",
        "            gt = [_ for cId in p.catIds for _ in self._gts[imgId,cId]]\n",
        "            dt = [_ for cId in p.catIds for _ in self._dts[imgId,cId]]\n",
        "        if len(gt) == 0 and len(dt) ==0:\n",
        "            return []\n",
        "        inds = np.argsort([-d['score'] for d in dt], kind='mergesort')\n",
        "        dt = [dt[i] for i in inds]\n",
        "        if len(dt) > p.maxDets[-1]:\n",
        "            dt=dt[0:p.maxDets[-1]]\n",
        "\n",
        "        if p.iouType == 'segm':\n",
        "            g = [g['segmentation'] for g in gt]\n",
        "            d = [d['segmentation'] for d in dt]\n",
        "        elif p.iouType == 'bbox':\n",
        "            g = [g['bbox'] for g in gt]\n",
        "            d = [d['bbox'] for d in dt]\n",
        "        else:\n",
        "            raise Exception('unknown iouType for iou computation')\n",
        "\n",
        "        # compute iou between each dt and gt region\n",
        "        iscrowd = [int(o['iscrowd']) for o in gt]\n",
        "        ious = maskUtils.iou(d,g,iscrowd)\n",
        "        return ious\n",
        "\n",
        "    def computeOks(self, imgId, catId):\n",
        "        p = self.params\n",
        "        # dimention here should be Nxm\n",
        "        gts = self._gts[imgId, catId]\n",
        "        dts = self._dts[imgId, catId]\n",
        "        inds = np.argsort([-d['score'] for d in dts], kind='mergesort')\n",
        "        dts = [dts[i] for i in inds]\n",
        "        if len(dts) > p.maxDets[-1]:\n",
        "            dts = dts[0:p.maxDets[-1]]\n",
        "        # if len(gts) == 0 and len(dts) == 0:\n",
        "        if len(gts) == 0 or len(dts) == 0:\n",
        "            return []\n",
        "        ious = np.zeros((len(dts), len(gts)))\n",
        "        sigmas = np.array([.26, .25, .25, .35, .35, .79, .79, .72, .72, .62,.62, 1.07, 1.07, .87, .87, .89, .89])/10.0\n",
        "        vars = (sigmas * 2)**2\n",
        "        k = len(sigmas)\n",
        "        # compute oks between each detection and ground truth object\n",
        "        for j, gt in enumerate(gts):\n",
        "            # create bounds for ignore regions(double the gt bbox)\n",
        "            g = np.array(gt['keypoints'])\n",
        "            xg = g[0::3]; yg = g[1::3]; vg = g[2::3]\n",
        "            k1 = np.count_nonzero(vg > 0)\n",
        "            bb = gt['bbox']\n",
        "            x0 = bb[0] - bb[2]; x1 = bb[0] + bb[2] * 2\n",
        "            y0 = bb[1] - bb[3]; y1 = bb[1] + bb[3] * 2\n",
        "            for i, dt in enumerate(dts):\n",
        "                d = np.array(dt['keypoints'])\n",
        "                xd = d[0::3]; yd = d[1::3]\n",
        "                if k1>0:\n",
        "                    # measure the per-keypoint distance if keypoints visible\n",
        "                    dx = xd - xg\n",
        "                    dy = yd - yg\n",
        "                else:\n",
        "                    # measure minimum distance to keypoints in (x0,y0) & (x1,y1)\n",
        "                    z = np.zeros((k))\n",
        "                    dx = np.max((z, x0-xd),axis=0)+np.max((z, xd-x1),axis=0)\n",
        "                    dy = np.max((z, y0-yd),axis=0)+np.max((z, yd-y1),axis=0)\n",
        "                e = (dx**2 + dy**2) / vars / (gt['area']+np.spacing(1)) / 2\n",
        "                if k1 > 0:\n",
        "                    e=e[vg > 0]\n",
        "                ious[i, j] = np.sum(np.exp(-e)) / e.shape[0]\n",
        "        return ious\n",
        "\n",
        "    def evaluateImg(self, imgId, catId, aRng, maxDet):\n",
        "        '''\n",
        "        perform evaluation for single category and image\n",
        "        :return: dict (single image results)\n",
        "        '''\n",
        "        p = self.params\n",
        "        if p.useCats:\n",
        "            gt = self._gts[imgId,catId]\n",
        "            dt = self._dts[imgId,catId]\n",
        "        else:\n",
        "            gt = [_ for cId in p.catIds for _ in self._gts[imgId,cId]]\n",
        "            dt = [_ for cId in p.catIds for _ in self._dts[imgId,cId]]\n",
        "        if len(gt) == 0 and len(dt) ==0:\n",
        "            return None\n",
        "\n",
        "        for g in gt:\n",
        "            if g['ignore'] or (g['area']<aRng[0] or g['area']>aRng[1]):\n",
        "                g['_ignore'] = 1\n",
        "            else:\n",
        "                g['_ignore'] = 0\n",
        "\n",
        "        # sort dt highest score first, sort gt ignore last\n",
        "        gtind = np.argsort([g['_ignore'] for g in gt], kind='mergesort')\n",
        "        gt = [gt[i] for i in gtind]\n",
        "        dtind = np.argsort([-d['score'] for d in dt], kind='mergesort')\n",
        "        dt = [dt[i] for i in dtind[0:maxDet]]\n",
        "        iscrowd = [int(o['iscrowd']) for o in gt]\n",
        "        # load computed ious\n",
        "        ious = self.ious[imgId, catId][:, gtind] if len(self.ious[imgId, catId]) > 0 else self.ious[imgId, catId]\n",
        "\n",
        "        T = len(p.iouThrs)\n",
        "        G = len(gt)\n",
        "        D = len(dt)\n",
        "        gtm  = np.zeros((T,G))\n",
        "        dtm  = np.zeros((T,D))\n",
        "        gtIg = np.array([g['_ignore'] for g in gt])\n",
        "        dtIg = np.zeros((T,D))\n",
        "        if not len(ious)==0:\n",
        "            for tind, t in enumerate(p.iouThrs):\n",
        "                for dind, d in enumerate(dt):\n",
        "                    # information about best match so far (m=-1 -> unmatched)\n",
        "                    iou = min([t,1-1e-10])\n",
        "                    m   = -1\n",
        "                    for gind, g in enumerate(gt):\n",
        "                        # if this gt already matched, and not a crowd, continue\n",
        "                        if gtm[tind,gind]>0 and not iscrowd[gind]:\n",
        "                            continue\n",
        "                        # if dt matched to reg gt, and on ignore gt, stop\n",
        "                        if m>-1 and gtIg[m]==0 and gtIg[gind]==1:\n",
        "                            break\n",
        "                        # continue to next gt unless better match made\n",
        "                        if ious[dind,gind] < iou:\n",
        "                            continue\n",
        "                        # if match successful and best so far, store appropriately\n",
        "                        iou=ious[dind,gind]\n",
        "                        m=gind\n",
        "                    # if match made store id of match for both dt and gt\n",
        "                    if m ==-1:\n",
        "                        continue\n",
        "                    dtIg[tind,dind] = gtIg[m]\n",
        "                    dtm[tind,dind]  = gt[m]['id']\n",
        "                    gtm[tind,m]     = d['id']\n",
        "        # set unmatched detections outside of area range to ignore\n",
        "        a = np.array([d['area']<aRng[0] or d['area']>aRng[1] for d in dt]).reshape((1, len(dt)))\n",
        "        dtIg = np.logical_or(dtIg, np.logical_and(dtm==0, np.repeat(a,T,0)))\n",
        "        # store results for given image and category\n",
        "        return {\n",
        "                'image_id':     imgId,\n",
        "                'category_id':  catId,\n",
        "                'aRng':         aRng,\n",
        "                'maxDet':       maxDet,\n",
        "                'dtIds':        [d['id'] for d in dt],\n",
        "                'gtIds':        [g['id'] for g in gt],\n",
        "                'dtMatches':    dtm,\n",
        "                'gtMatches':    gtm,\n",
        "                'dtScores':     [d['score'] for d in dt],\n",
        "                'gtIgnore':     gtIg,\n",
        "                'dtIgnore':     dtIg,\n",
        "            }\n",
        "\n",
        "    def accumulate(self, p = None):\n",
        "        '''\n",
        "        Accumulate per image evaluation results and store the result in self.eval\n",
        "        :param p: input params for evaluation\n",
        "        :return: None\n",
        "        '''\n",
        "        print('Accumulating evaluation results...')\n",
        "        tic = time.time()\n",
        "        if not self.evalImgs:\n",
        "            print('Please run evaluate() first')\n",
        "        # allows input customized parameters\n",
        "        if p is None:\n",
        "            p = self.params\n",
        "        p.catIds = p.catIds if p.useCats == 1 else [-1]\n",
        "        T           = len(p.iouThrs)\n",
        "        R           = len(p.recThrs)\n",
        "        K           = len(p.catIds) if p.useCats else 1\n",
        "        A           = len(p.areaRng)\n",
        "        M           = len(p.maxDets)\n",
        "        precision   = -np.ones((T,R,K,A,M)) # -1 for the precision of absent categories\n",
        "        recall      = -np.ones((T,K,A,M))\n",
        "        scores      = -np.ones((T,R,K,A,M))\n",
        "\n",
        "        # create dictionary for future indexing\n",
        "        _pe = self._paramsEval\n",
        "        catIds = _pe.catIds if _pe.useCats else [-1]\n",
        "        setK = set(catIds)\n",
        "        setA = set(map(tuple, _pe.areaRng))\n",
        "        setM = set(_pe.maxDets)\n",
        "        setI = set(_pe.imgIds)\n",
        "        # get inds to evaluate\n",
        "        k_list = [n for n, k in enumerate(p.catIds)  if k in setK]\n",
        "        m_list = [m for n, m in enumerate(p.maxDets) if m in setM]\n",
        "        a_list = [n for n, a in enumerate(map(lambda x: tuple(x), p.areaRng)) if a in setA]\n",
        "        i_list = [n for n, i in enumerate(p.imgIds)  if i in setI]\n",
        "        I0 = len(_pe.imgIds)\n",
        "        A0 = len(_pe.areaRng)\n",
        "        # retrieve E at each category, area range, and max number of detections\n",
        "        for k, k0 in enumerate(k_list):\n",
        "            Nk = k0*A0*I0\n",
        "            for a, a0 in enumerate(a_list):\n",
        "                Na = a0*I0\n",
        "                for m, maxDet in enumerate(m_list):\n",
        "                    E = [self.evalImgs[Nk + Na + i] for i in i_list]\n",
        "                    E = [e for e in E if not e is None]\n",
        "                    if len(E) == 0:\n",
        "                        continue\n",
        "                    dtScores = np.concatenate([e['dtScores'][0:maxDet] for e in E])\n",
        "\n",
        "                    # different sorting method generates slightly different results.\n",
        "                    # mergesort is used to be consistent as Matlab implementation.\n",
        "                    inds = np.argsort(-dtScores, kind='mergesort')\n",
        "                    dtScoresSorted = dtScores[inds]\n",
        "\n",
        "                    dtm  = np.concatenate([e['dtMatches'][:,0:maxDet] for e in E], axis=1)[:,inds]\n",
        "                    dtIg = np.concatenate([e['dtIgnore'][:,0:maxDet]  for e in E], axis=1)[:,inds]\n",
        "                    gtIg = np.concatenate([e['gtIgnore'] for e in E])\n",
        "                    npig = np.count_nonzero(gtIg==0 )\n",
        "                    if npig == 0:\n",
        "                        continue\n",
        "                    tps = np.logical_and(               dtm,  np.logical_not(dtIg) )\n",
        "                    fps = np.logical_and(np.logical_not(dtm), np.logical_not(dtIg) )\n",
        "\n",
        "                    tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)\n",
        "                    fp_sum = np.cumsum(fps, axis=1).astype(dtype=np.float)\n",
        "                    for t, (tp, fp) in enumerate(zip(tp_sum, fp_sum)):\n",
        "                        tp = np.array(tp)\n",
        "                        fp = np.array(fp)\n",
        "                        nd = len(tp)\n",
        "                        rc = tp / npig\n",
        "                        pr = tp / (fp+tp+np.spacing(1))\n",
        "                        q  = np.zeros((R,))\n",
        "                        ss = np.zeros((R,))\n",
        "\n",
        "                        if nd:\n",
        "                            recall[t,k,a,m] = rc[-1]\n",
        "                        else:\n",
        "                            recall[t,k,a,m] = 0\n",
        "\n",
        "                        # numpy is slow without cython optimization for accessing elements\n",
        "                        # use python array gets significant speed improvement\n",
        "                        pr = pr.tolist(); q = q.tolist()\n",
        "\n",
        "                        for i in range(nd-1, 0, -1):\n",
        "                            if pr[i] > pr[i-1]:\n",
        "                                pr[i-1] = pr[i]\n",
        "\n",
        "                        inds = np.searchsorted(rc, p.recThrs, side='left')\n",
        "                        try:\n",
        "                            for ri, pi in enumerate(inds):\n",
        "                                q[ri] = pr[pi]\n",
        "                                ss[ri] = dtScoresSorted[pi]\n",
        "                        except:\n",
        "                            pass\n",
        "                        precision[t,:,k,a,m] = np.array(q)\n",
        "                        scores[t,:,k,a,m] = np.array(ss)\n",
        "        self.eval = {\n",
        "            'params': p,\n",
        "            'counts': [T, R, K, A, M],\n",
        "            'date': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'precision': precision,\n",
        "            'recall':   recall,\n",
        "            'scores': scores,\n",
        "        }\n",
        "        toc = time.time()\n",
        "        print('DONE (t={:0.2f}s).'.format( toc-tic))\n",
        "\n",
        "    def summarize(self):\n",
        "        '''\n",
        "        Compute and display summary metrics for evaluation results.\n",
        "        Note this functin can *only* be applied on the default parameter setting\n",
        "        '''\n",
        "        def _summarize( ap=1, iouThr=None, areaRng='all', maxDets=100 ):\n",
        "            p = self.params\n",
        "            iStr = ' {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}'\n",
        "            titleStr = 'Average Precision' if ap == 1 else 'Average Recall'\n",
        "            typeStr = '(AP)' if ap==1 else '(AR)'\n",
        "            iouStr = '{:0.2f}:{:0.2f}'.format(p.iouThrs[0], p.iouThrs[-1]) \\\n",
        "                if iouThr is None else '{:0.2f}'.format(iouThr)\n",
        "\n",
        "            aind = [i for i, aRng in enumerate(p.areaRngLbl) if aRng == areaRng]\n",
        "            mind = [i for i, mDet in enumerate(p.maxDets) if mDet == maxDets]\n",
        "            if ap == 1:\n",
        "                # dimension of precision: [TxRxKxAxM]\n",
        "                s = self.eval['precision']\n",
        "                # IoU\n",
        "                if iouThr is not None:\n",
        "                    t = np.where(iouThr == p.iouThrs)[0]\n",
        "                    s = s[t]\n",
        "                s = s[:,:,:,aind,mind]\n",
        "            else:\n",
        "                # dimension of recall: [TxKxAxM]\n",
        "                s = self.eval['recall']\n",
        "                if iouThr is not None:\n",
        "                    t = np.where(iouThr == p.iouThrs)[0]\n",
        "                    s = s[t]\n",
        "                s = s[:,:,aind,mind]\n",
        "            if len(s[s>-1])==0:\n",
        "                mean_s = -1\n",
        "            else:\n",
        "                mean_s = np.mean(s[s>-1])\n",
        "            print(iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s))\n",
        "            return mean_s\n",
        "        def _summarizeDets():\n",
        "            stats = np.zeros((12,))\n",
        "            stats[0] = _summarize(1)\n",
        "            stats[1] = _summarize(1, iouThr=.5, maxDets=self.params.maxDets[2])\n",
        "            stats[2] = _summarize(1, iouThr=.75, maxDets=self.params.maxDets[2])\n",
        "            stats[3] = _summarize(1, areaRng='small', maxDets=self.params.maxDets[2])\n",
        "            stats[4] = _summarize(1, areaRng='medium', maxDets=self.params.maxDets[2])\n",
        "            stats[5] = _summarize(1, areaRng='large', maxDets=self.params.maxDets[2])\n",
        "            stats[6] = _summarize(0, maxDets=self.params.maxDets[0])\n",
        "            stats[7] = _summarize(0, maxDets=self.params.maxDets[1])\n",
        "            stats[8] = _summarize(0, maxDets=self.params.maxDets[2])\n",
        "            stats[9] = _summarize(0, areaRng='small', maxDets=self.params.maxDets[2])\n",
        "            stats[10] = _summarize(0, areaRng='medium', maxDets=self.params.maxDets[2])\n",
        "            stats[11] = _summarize(0, areaRng='large', maxDets=self.params.maxDets[2])\n",
        "            return stats\n",
        "        def _summarizeKps():\n",
        "            stats = np.zeros((10,))\n",
        "            stats[0] = _summarize(1, maxDets=20)\n",
        "            stats[1] = _summarize(1, maxDets=20, iouThr=.5)\n",
        "            stats[2] = _summarize(1, maxDets=20, iouThr=.75)\n",
        "            stats[3] = _summarize(1, maxDets=20, areaRng='medium')\n",
        "            stats[4] = _summarize(1, maxDets=20, areaRng='large')\n",
        "            stats[5] = _summarize(0, maxDets=20)\n",
        "            stats[6] = _summarize(0, maxDets=20, iouThr=.5)\n",
        "            stats[7] = _summarize(0, maxDets=20, iouThr=.75)\n",
        "            stats[8] = _summarize(0, maxDets=20, areaRng='medium')\n",
        "            stats[9] = _summarize(0, maxDets=20, areaRng='large')\n",
        "            return stats\n",
        "        if not self.eval:\n",
        "            raise Exception('Please run accumulate() first')\n",
        "        iouType = self.params.iouType\n",
        "        if iouType == 'segm' or iouType == 'bbox':\n",
        "            summarize = _summarizeDets\n",
        "        elif iouType == 'keypoints':\n",
        "            summarize = _summarizeKps\n",
        "        self.stats = summarize()\n",
        "\n",
        "    def __str__(self):\n",
        "        self.summarize()\n",
        "\n",
        "class Params:\n",
        "    '''\n",
        "    Params for coco evaluation api\n",
        "    '''\n",
        "    def setDetParams(self):\n",
        "        self.imgIds = []\n",
        "        self.catIds = []\n",
        "        # np.arange causes trouble.  the data point on arange is slightly larger than the true value\n",
        "        self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05).astype(np.int) + 1, endpoint=True)\n",
        "        self.recThrs = np.linspace(.0, 1.00, np.round((1.00 - .0) / .01).astype(np.int) + 1, endpoint=True)\n",
        "        self.maxDets = [1, 10, 100]\n",
        "        self.areaRng = [[0 ** 2, 1e5 ** 2], [0 ** 2, 32 ** 2], [32 ** 2, 96 ** 2], [96 ** 2, 1e5 ** 2]]\n",
        "        self.areaRngLbl = ['all', 'small', 'medium', 'large']\n",
        "        self.useCats = 1\n",
        "\n",
        "    def setKpParams(self):\n",
        "        self.imgIds = []\n",
        "        self.catIds = []\n",
        "        # np.arange causes trouble.  the data point on arange is slightly larger than the true value\n",
        "        self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05).astype(np.int) + 1, endpoint=True)\n",
        "        self.recThrs = np.linspace(.0, 1.00, np.round((1.00 - .0) / .01).astype(np.int) + 1, endpoint=True)\n",
        "        self.maxDets = [20]\n",
        "        self.areaRng = [[0 ** 2, 1e5 ** 2], [32 ** 2, 96 ** 2], [96 ** 2, 1e5 ** 2]]\n",
        "        self.areaRngLbl = ['all', 'medium', 'large']\n",
        "        self.useCats = 1\n",
        "\n",
        "    def __init__(self, iouType='segm'):\n",
        "        if iouType == 'segm' or iouType == 'bbox':\n",
        "            self.setDetParams()\n",
        "        elif iouType == 'keypoints':\n",
        "            self.setKpParams()\n",
        "        else:\n",
        "            raise Exception('iouType not supported')\n",
        "        self.iouType = iouType\n",
        "        # useSegm is deprecated\n",
        "        self.useSegm = None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/omkardhawal21/object_detection_demo'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 2000  # 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1",
        "colab_type": "text"
      },
      "source": [
        "## Clone the `object_detection_demo` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "05103fdf-c7b3-489d-8ea1-7e32f0425858"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'object_detection_demo' already exists and is not an empty directory.\n",
            "/content/object_detection_demo\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns",
        "colab_type": "text"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4abefe9b-4f21-424a-f2d9-4ecdc68ddcf2"
      },
      "source": [
        "%cd /content\n",
        "!pip install tf_slim \n",
        "#below import added by me\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny",
        "colab_type": "text"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Use the following scripts to generate the `tfrecord` files.\n",
        "```bash\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezGDABRXXhPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "dc304cb2-7bbd-430b-ca0b-80a46a9339e9"
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "import tensorflow.compat.v1 as tf\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/object_detection_demo\n",
            "Successfully converted xml to csv.\n",
            "Generate `data/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0802 10:37:54.016159 140498355144576 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0802 10:37:54.328315 140498355144576 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/train.record\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0802 10:37:59.462777 140328252393344 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0802 10:37:59.494513 140328252393344 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n",
        "train_record_fname = '/content/object_detection_demo/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/object_detection_demo/data/annotations/label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8",
        "colab_type": "text"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "656a2b14-41e5-4e4a-e9df-52722afb3a8f"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "ce862a5f-4d5e-4927-eb87-a852e94e23b4"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 23 root   root  4.0K Aug  2 10:38 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d709f750-b8f7-4116-a0f9-82fad9a0cfd5"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD",
        "colab_type": "text"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HENwTPYRFxBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "9cb0a563-ab31-46c3-8fb3-ac8cd2b07247"
      },
      "source": [
        "!cat /content/object_detection_demo/data/annotations/label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "    id: 1\n",
            "    name: 'Elephant'\n",
            "}\n",
            "\n",
            "item {\n",
            "    id: 2\n",
            "    name: 'Monkey'\n",
            "}\n",
            "\n",
            "item {\n",
            "    id: 3\n",
            "    name: 'Person'\n",
            "}\n",
            "\n",
            "item {\n",
            "    id: 4\n",
            "    name: 'Pig'\n",
            "}\n",
            "\n",
            "item {\n",
            "    id: 5\n",
            "    name: 'Vehicle'\n",
            "}\n",
            "\n",
            "item {\n",
            "    id: 6\n",
            "    name: 'civet'\n",
            "}\n",
            "\n",
            "item {\n",
            "    id: 7\n",
            "    name: 'deer'\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk6aw7iaLMxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca593f99-1c9f-45b7-8455-82520e795fd0"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 7\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 2000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fcb35a90-0ac9-4618-8601-0b0d7614426b"
      },
      "source": [
        "#!cat {pipeline_fname}\n",
        "!cat /content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 7\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 2000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC7_syR1SJ9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f9b6a0f-5bcc-4d34-90bc-bff1b9e672b2"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0802 10:38:53.634673 139753048659840 model_lib.py:758] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
            "I0802 10:38:53.634933 139753048659840 config_util.py:552] Maybe overwriting train_steps: 2000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0802 10:38:53.635125 139753048659840 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0802 10:38:53.635262 139753048659840 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0802 10:38:53.635409 139753048659840 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0802 10:38:53.635573 139753048659840 model_lib.py:774] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0802 10:38:53.635717 139753048659840 model_lib.py:809] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a61c8ae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0802 10:38:53.636208 139753048659840 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a61c8ae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1a61c8f598>) includes params argument, but params are not passed to Estimator.\n",
            "W0802 10:38:53.637026 139753048659840 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1a61c8f598>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0802 10:38:53.637758 139753048659840 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0802 10:38:53.638004 139753048659840 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0802 10:38:53.638332 139753048659840 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0802 10:38:53.651505 139753048659840 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0802 10:38:53.691331 139753048659840 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0802 10:38:53.697590 139753048659840 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0802 10:38:53.720803 139753048659840 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1a61c979b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0802 10:38:53.757323 139753048659840 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1a61c979b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f1a87dc96a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0802 10:38:54.001875 139753048659840 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f1a87dc96a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0802 10:38:54.009372 139753048659840 deprecation.py:323] From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0802 10:38:54.018458 139753048659840 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0802 10:38:54.140282 139753048659840 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0802 10:38:55.196971 139753048659840 deprecation.py:323] From /content/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 10:38:55.767650 139753048659840 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0802 10:38:56.020020 139753048659840 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:38:59.438450 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:38:59.476406 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:38:59.514806 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:38:59.553885 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:38:59.595477 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:38:59.635088 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0802 10:39:04.751723 139753048659840 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 10:39:12.584754 139753048659840 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0802 10:39:12.586469 139753048659840 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 10:39:16.586933 139753048659840 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 10:39:16.600984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-08-02 10:39:16.601332: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15188380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 10:39:16.601383: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-02 10:39:16.606374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-02 10:39:16.722324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:39:16.723214: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x151881c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 10:39:16.723249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-08-02 10:39:16.724601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:39:16.725334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 10:39:16.725745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 10:39:16.950076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-02 10:39:17.084890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-02 10:39:17.108971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-02 10:39:17.383677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-02 10:39:17.403490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-02 10:39:17.933715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 10:39:17.933992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:39:17.934888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:39:17.935645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-08-02 10:39:17.940006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 10:39:17.941896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 10:39:17.941931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-08-02 10:39:17.941957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-08-02 10:39:17.943540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:39:17.944445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:39:17.945204: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-02 10:39:17.945260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 10:39:27.442881 139753048659840 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 10:39:27.813678 139753048659840 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0802 10:39:38.540175 139753048659840 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-08-02 10:39:48.281979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 10:39:52.339408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 35.584087, step = 0\n",
            "I0802 10:39:55.756676 139753048659840 basic_session_run_hooks.py:262] loss = 35.584087, step = 0\n",
            "INFO:tensorflow:global_step/sec: 2.22554\n",
            "I0802 10:40:40.688382 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.22554\n",
            "INFO:tensorflow:loss = 9.440012, step = 100 (44.933 sec)\n",
            "I0802 10:40:40.689640 139753048659840 basic_session_run_hooks.py:260] loss = 9.440012, step = 100 (44.933 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.48405\n",
            "I0802 10:41:20.945230 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.48405\n",
            "INFO:tensorflow:loss = 9.986248, step = 200 (40.257 sec)\n",
            "I0802 10:41:20.946750 139753048659840 basic_session_run_hooks.py:260] loss = 9.986248, step = 200 (40.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.44456\n",
            "I0802 10:42:01.852447 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.44456\n",
            "INFO:tensorflow:loss = 9.465597, step = 300 (40.907 sec)\n",
            "I0802 10:42:01.853712 139753048659840 basic_session_run_hooks.py:260] loss = 9.465597, step = 300 (40.907 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.45558\n",
            "I0802 10:42:42.575926 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.45558\n",
            "INFO:tensorflow:loss = 8.077219, step = 400 (40.724 sec)\n",
            "I0802 10:42:42.577238 139753048659840 basic_session_run_hooks.py:260] loss = 8.077219, step = 400 (40.724 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.44069\n",
            "I0802 10:43:23.548005 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.44069\n",
            "INFO:tensorflow:loss = 7.320049, step = 500 (40.972 sec)\n",
            "I0802 10:43:23.549458 139753048659840 basic_session_run_hooks.py:260] loss = 7.320049, step = 500 (40.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.45262\n",
            "I0802 10:44:04.320799 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.45262\n",
            "INFO:tensorflow:loss = 7.6803865, step = 600 (40.773 sec)\n",
            "I0802 10:44:04.322314 139753048659840 basic_session_run_hooks.py:260] loss = 7.6803865, step = 600 (40.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.42819\n",
            "I0802 10:44:45.503795 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.42819\n",
            "INFO:tensorflow:loss = 8.132202, step = 700 (41.183 sec)\n",
            "I0802 10:44:45.505167 139753048659840 basic_session_run_hooks.py:260] loss = 8.132202, step = 700 (41.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.4232\n",
            "I0802 10:45:26.771540 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.4232\n",
            "INFO:tensorflow:loss = 7.438477, step = 800 (41.267 sec)\n",
            "I0802 10:45:26.772653 139753048659840 basic_session_run_hooks.py:260] loss = 7.438477, step = 800 (41.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.41879\n",
            "I0802 10:46:08.114567 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.41879\n",
            "INFO:tensorflow:loss = 8.0049095, step = 900 (41.343 sec)\n",
            "I0802 10:46:08.115798 139753048659840 basic_session_run_hooks.py:260] loss = 8.0049095, step = 900 (41.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.45323\n",
            "I0802 10:46:48.877032 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.45323\n",
            "INFO:tensorflow:loss = 7.2383204, step = 1000 (40.763 sec)\n",
            "I0802 10:46:48.878501 139753048659840 basic_session_run_hooks.py:260] loss = 7.2383204, step = 1000 (40.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.45638\n",
            "I0802 10:47:29.587324 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.45638\n",
            "INFO:tensorflow:loss = 7.214088, step = 1100 (40.710 sec)\n",
            "I0802 10:47:29.588924 139753048659840 basic_session_run_hooks.py:260] loss = 7.214088, step = 1100 (40.710 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.42539\n",
            "I0802 10:48:10.817873 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.42539\n",
            "INFO:tensorflow:loss = 8.154686, step = 1200 (41.230 sec)\n",
            "I0802 10:48:10.819276 139753048659840 basic_session_run_hooks.py:260] loss = 8.154686, step = 1200 (41.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.45829\n",
            "I0802 10:48:51.496530 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.45829\n",
            "INFO:tensorflow:loss = 6.010241, step = 1300 (40.678 sec)\n",
            "I0802 10:48:51.497685 139753048659840 basic_session_run_hooks.py:260] loss = 6.010241, step = 1300 (40.678 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.3918\n",
            "I0802 10:49:33.305932 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.3918\n",
            "INFO:tensorflow:loss = 8.15273, step = 1400 (41.810 sec)\n",
            "I0802 10:49:33.307472 139753048659840 basic_session_run_hooks.py:260] loss = 8.15273, step = 1400 (41.810 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1420 into training/model.ckpt.\n",
            "I0802 10:49:40.963662 139753048659840 basic_session_run_hooks.py:606] Saving checkpoints for 1420 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1a5050e160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0802 10:49:42.714650 139753048659840 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1a5050e160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1a5b3bbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0802 10:49:42.936987 139753048659840 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1a5b3bbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 10:49:43.577579 139753048659840 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:49:46.336493 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:49:46.383292 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:49:46.421452 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:49:46.460624 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:49:46.500424 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:49:46.538701 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:855: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0802 10:49:47.676804 139753048659840 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:855: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0802 10:49:47.929446 139753048659840 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 10:49:48.604380 139753048659840 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-02T10:49:48Z\n",
            "I0802 10:49:48.625416 139753048659840 evaluation.py:255] Starting evaluation at 2020-08-02T10:49:48Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 10:49:49.187804 139753048659840 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 10:49:49.189238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:49:49.189919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 10:49:49.190033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 10:49:49.190105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-02 10:49:49.190167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-02 10:49:49.190222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-02 10:49:49.190282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-02 10:49:49.190367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-02 10:49:49.190427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 10:49:49.190569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:49:49.191299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:49:49.191890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-08-02 10:49:49.192087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 10:49:49.192118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-08-02 10:49:49.192137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-08-02 10:49:49.192303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:49:49.192999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:49:49.193610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1420\n",
            "I0802 10:49:49.195024 139753048659840 saver.py:1284] Restoring parameters from training/model.ckpt-1420\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 10:49:50.179417 139753048659840 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 10:49:50.319175 139753048659840 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 44 images.\n",
            "I0802 10:49:55.159129 139749748381440 coco_evaluation.py:237] Performing evaluation on 44 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0802 10:49:55.159803 139749748381440 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0802 10:49:55.162425 139749748381440 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.40s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.12s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.059\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-02-10:49:56\n",
            "I0802 10:49:56.346844 139753048659840 evaluation.py:275] Finished evaluation at 2020-08-02-10:49:56\n",
            "INFO:tensorflow:Saving dict for global step 1420: DetectionBoxes_Precision/mAP = 0.0019221089, DetectionBoxes_Precision/mAP (large) = 0.0023832577, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.006882074, DetectionBoxes_Precision/mAP@.75IOU = 0.00028292075, DetectionBoxes_Recall/AR@1 = 0.015113779, DetectionBoxes_Recall/AR@10 = 0.039213233, DetectionBoxes_Recall/AR@100 = 0.050024044, DetectionBoxes_Recall/AR@100 (large) = 0.05890922, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 12.821182, Loss/localization_loss = 2.38461, Loss/regularization_loss = 0.313535, Loss/total_loss = 15.519326, global_step = 1420, learning_rate = 0.004, loss = 15.519326\n",
            "I0802 10:49:56.347266 139753048659840 estimator.py:2049] Saving dict for global step 1420: DetectionBoxes_Precision/mAP = 0.0019221089, DetectionBoxes_Precision/mAP (large) = 0.0023832577, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.006882074, DetectionBoxes_Precision/mAP@.75IOU = 0.00028292075, DetectionBoxes_Recall/AR@1 = 0.015113779, DetectionBoxes_Recall/AR@10 = 0.039213233, DetectionBoxes_Recall/AR@100 = 0.050024044, DetectionBoxes_Recall/AR@100 (large) = 0.05890922, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 12.821182, Loss/localization_loss = 2.38461, Loss/regularization_loss = 0.313535, Loss/total_loss = 15.519326, global_step = 1420, learning_rate = 0.004, loss = 15.519326\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1420: training/model.ckpt-1420\n",
            "I0802 10:49:57.552110 139753048659840 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1420: training/model.ckpt-1420\n",
            "INFO:tensorflow:global_step/sec: 1.74762\n",
            "I0802 10:50:30.526682 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 1.74762\n",
            "INFO:tensorflow:loss = 7.1555448, step = 1500 (57.220 sec)\n",
            "I0802 10:50:30.527860 139753048659840 basic_session_run_hooks.py:260] loss = 7.1555448, step = 1500 (57.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.42028\n",
            "I0802 10:51:11.844266 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.42028\n",
            "INFO:tensorflow:loss = 7.641831, step = 1600 (41.318 sec)\n",
            "I0802 10:51:11.845735 139753048659840 basic_session_run_hooks.py:260] loss = 7.641831, step = 1600 (41.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.44831\n",
            "I0802 10:51:52.688852 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.44831\n",
            "INFO:tensorflow:loss = 7.685711, step = 1700 (40.845 sec)\n",
            "I0802 10:51:52.690403 139753048659840 basic_session_run_hooks.py:260] loss = 7.685711, step = 1700 (40.845 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.38042\n",
            "I0802 10:52:34.698310 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.38042\n",
            "INFO:tensorflow:loss = 7.7740264, step = 1800 (42.010 sec)\n",
            "I0802 10:52:34.700333 139753048659840 basic_session_run_hooks.py:260] loss = 7.7740264, step = 1800 (42.010 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.46811\n",
            "I0802 10:53:15.215143 139753048659840 basic_session_run_hooks.py:692] global_step/sec: 2.46811\n",
            "INFO:tensorflow:loss = 6.871754, step = 1900 (40.516 sec)\n",
            "I0802 10:53:15.216495 139753048659840 basic_session_run_hooks.py:260] loss = 6.871754, step = 1900 (40.516 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into training/model.ckpt.\n",
            "I0802 10:53:56.096186 139753048659840 basic_session_run_hooks.py:606] Saving checkpoints for 2000 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0802 10:53:57.673484 139753048659840 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1a505cd908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0802 10:53:57.746796 139753048659840 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1a505cd908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1a00811d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0802 10:53:57.963687 139753048659840 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1a00811d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 10:53:58.638341 139753048659840 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:01.396721 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:01.436504 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:01.479430 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:01.524235 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:01.568963 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:01.610678 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 10:54:03.649542 139753048659840 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-02T10:54:03Z\n",
            "I0802 10:54:03.670708 139753048659840 evaluation.py:255] Starting evaluation at 2020-08-02T10:54:03Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 10:54:04.205519 139753048659840 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 10:54:04.206466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:04.207145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 10:54:04.207254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 10:54:04.207320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-02 10:54:04.207385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-02 10:54:04.207463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-02 10:54:04.207507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-02 10:54:04.207549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-02 10:54:04.207597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 10:54:04.207773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:04.208500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:04.209104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-08-02 10:54:04.209162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 10:54:04.209184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-08-02 10:54:04.209199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-08-02 10:54:04.209403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:04.210125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:04.210656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2000\n",
            "I0802 10:54:04.211821 139753048659840 saver.py:1284] Restoring parameters from training/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 10:54:05.241235 139753048659840 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 10:54:05.376996 139753048659840 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 44 images.\n",
            "I0802 10:54:09.774969 139751003842304 coco_evaluation.py:237] Performing evaluation on 44 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0802 10:54:09.775599 139751003842304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0802 10:54:09.777980 139751003842304 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.11s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.042\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-02-10:54:10\n",
            "I0802 10:54:10.953773 139753048659840 evaluation.py:275] Finished evaluation at 2020-08-02-10:54:10\n",
            "INFO:tensorflow:Saving dict for global step 2000: DetectionBoxes_Precision/mAP = 0.0027031626, DetectionBoxes_Precision/mAP (large) = 0.0034613288, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.009315683, DetectionBoxes_Precision/mAP@.75IOU = 0.000109647546, DetectionBoxes_Recall/AR@1 = 0.014230557, DetectionBoxes_Recall/AR@10 = 0.023239566, DetectionBoxes_Recall/AR@100 = 0.034050375, DetectionBoxes_Recall/AR@100 (large) = 0.042073656, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 11.191977, Loss/localization_loss = 2.3367708, Loss/regularization_loss = 0.31393057, Loss/total_loss = 13.842676, global_step = 2000, learning_rate = 0.004, loss = 13.842676\n",
            "I0802 10:54:10.954127 139753048659840 estimator.py:2049] Saving dict for global step 2000: DetectionBoxes_Precision/mAP = 0.0027031626, DetectionBoxes_Precision/mAP (large) = 0.0034613288, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.009315683, DetectionBoxes_Precision/mAP@.75IOU = 0.000109647546, DetectionBoxes_Recall/AR@1 = 0.014230557, DetectionBoxes_Recall/AR@10 = 0.023239566, DetectionBoxes_Recall/AR@100 = 0.034050375, DetectionBoxes_Recall/AR@100 (large) = 0.042073656, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 11.191977, Loss/localization_loss = 2.3367708, Loss/regularization_loss = 0.31393057, Loss/total_loss = 13.842676, global_step = 2000, learning_rate = 0.004, loss = 13.842676\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: training/model.ckpt-2000\n",
            "I0802 10:54:10.958129 139753048659840 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2000: training/model.ckpt-2000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0802 10:54:10.958893 139753048659840 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 10:54:11.283351 139753048659840 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:14.026336 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:14.065183 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:14.103731 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:14.141989 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:14.180482 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 10:54:14.218525 139753048659840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 10:54:15.748271 139753048659840 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0802 10:54:15.748653 139753048659840 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0802 10:54:15.749553 139753048659840 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0802 10:54:15.749759 139753048659840 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0802 10:54:15.749894 139753048659840 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0802 10:54:15.750026 139753048659840 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0802 10:54:15.750168 139753048659840 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2020-08-02 10:54:15.750852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:15.751497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 10:54:15.751583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 10:54:15.751629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-02 10:54:15.751675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-02 10:54:15.751723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-02 10:54:15.751765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-02 10:54:15.751805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-02 10:54:15.751846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 10:54:15.751988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:15.752698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:15.753257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-08-02 10:54:15.753318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 10:54:15.753345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-08-02 10:54:15.753360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-08-02 10:54:15.753543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:15.754155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 10:54:15.754712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2000\n",
            "I0802 10:54:15.757777 139753048659840 saver.py:1284] Restoring parameters from training/model.ckpt-2000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0802 10:54:16.266961 139753048659840 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0802 10:54:16.267239 139753048659840 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1596365650'/saved_model.pb\n",
            "I0802 10:54:17.203752 139753048659840 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1596365650'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 7.2379117.\n",
            "I0802 10:54:17.577284 139753048659840 estimator.py:371] Loss for final step: 7.2379117.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "1da63705-1ce9-419e-be88-ade732ae927b"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1596364753.aff83c7a95f5\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-0.data-00000-of-00001\n",
            "model.ckpt-0.index\n",
            "model.ckpt-0.meta\n",
            "model.ckpt-1420.data-00000-of-00001\n",
            "model.ckpt-1420.index\n",
            "model.ckpt-1420.meta\n",
            "model.ckpt-2000.data-00000-of-00001\n",
            "model.ckpt-2000.index\n",
            "model.ckpt-2000.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Nrqw3nqnCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Legacy way of training(also works).\n",
        "# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa",
        "colab_type": "text"
      },
      "source": [
        "## Exporting a Tflite Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "951941f3-74d4-4002-998a-567e8763d98c"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "\n",
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "--pipeline_config_path {pipeline_fname} \\\n",
        "--trained_checkpoint_prefix {last_model_path} \\\n",
        "--output_directory \"/content/object_detection_demo/\" \\\n",
        "--add_postprocessing_op True \\\n",
        "--max_detections 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-2000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0802 11:03:09.440565 139680823289728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 11:03:12.111107 139680823289728 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 11:03:12.149720 139680823289728 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 11:03:12.187459 139680823289728 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 11:03:12.225677 139680823289728 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 11:03:12.264406 139680823289728 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 11:03:12.304620 139680823289728 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "2020-08-02 11:03:12.471989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-02 11:03:12.493460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:12.494197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 11:03:12.494480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 11:03:12.496867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-02 11:03:12.498665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-02 11:03:12.503390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-02 11:03:12.505649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-02 11:03:12.518739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-02 11:03:12.531906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 11:03:12.532191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:12.533115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:12.533814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-08-02 11:03:12.548294: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-08-02 11:03:12.548539: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2610bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 11:03:12.548577: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-02 11:03:12.615505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:12.616433: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2610a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 11:03:12.616466: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-08-02 11:03:12.616659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:12.617375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 11:03:12.617459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 11:03:12.617501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-02 11:03:12.617548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-02 11:03:12.617588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-02 11:03:12.617627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-02 11:03:12.617669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-02 11:03:12.617712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 11:03:12.617837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:12.618582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:12.619317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-08-02 11:03:12.619410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 11:03:12.620984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 11:03:12.621028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-08-02 11:03:12.621070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-08-02 11:03:12.621294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:12.622164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:12.622867: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-02 11:03:12.622920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0802 11:03:13.108204 139680823289728 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-08-02 11:03:13.664657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:13.665462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 11:03:13.665560: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 11:03:13.665605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-02 11:03:13.665657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-02 11:03:13.665730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-02 11:03:13.665769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-02 11:03:13.665814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-02 11:03:13.665881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 11:03:13.666067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:13.666916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:13.667676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-08-02 11:03:13.667728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 11:03:13.667749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-08-02 11:03:13.667767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-08-02 11:03:13.667926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:13.668781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:13.669519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2000\n",
            "I0802 11:03:13.671251 139680823289728 saver.py:1284] Restoring parameters from training/model.ckpt-2000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0802 11:03:14.668195 139680823289728 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0802 11:03:14.668513 139680823289728 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 324 variables.\n",
            "I0802 11:03:14.967385 139680823289728 graph_util_impl.py:334] Froze 324 variables.\n",
            "INFO:tensorflow:Converted 324 variables to const ops.\n",
            "I0802 11:03:15.032541 139680823289728 graph_util_impl.py:394] Converted 324 variables to const ops.\n",
            "2020-08-02 11:03:15.125246: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQLWjabtkZBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "#    --input_type=image_tensor \\\n",
        "#    --pipeline_config_path={pipeline_fname} \\\n",
        "#    --output_directory=\"/content/object_detection_demo/\" \\\n",
        "#    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "5729ae46-5fb9-472f-a839-fbbcd149edcb"
      },
      "source": [
        "!ls /content/object_detection_demo/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t\t    requirements.txt\n",
            "deploy\t\t\t    resize_images.py\n",
            "generate_tfrecord.py\t    tensorflow_object_detection_training_colab.ipynb\n",
            "LICENSE\t\t\t    test\n",
            "local_inference_test.ipynb  tflite_graph.pb\n",
            "local_inference_test.py     tflite_graph.pbtxt\n",
            "new_sign.tflite\t\t    xml_to_csv.py\n",
            "README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1YO4_U5nY-U",
        "colab_type": "text"
      },
      "source": [
        "# Converting tflite_graph.pb to tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM0xBDtMnS0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "outputId": "9e9bb1e4-bf75-4536-e2b4-b7c1f2fc9bb5"
      },
      "source": [
        "!toco \\\n",
        " --graph_def_file \"/content/object_detection_demo/tflite_graph.pb\" \\\n",
        " --output_file /content/object_detection_demo/hope_sih_v4.tflite \\\n",
        " --input_shapes 1,300,300,3 \\\n",
        " --input_arrays normalized_input_image_tensor \\\n",
        " --output_arrays \"TFLite_Detection_PostProcess\",\"TFLite_Detection_PostProcess:1\",\"TFLite_Detection_PostProcess:2\",\"TFLite_Detection_PostProcess:3\" \\\n",
        " --inference_type FLOAT \\\n",
        " --allow_custom_ops"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-02 11:03:31.714071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-02 11:03:31.737644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:31.738429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 11:03:31.738712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 11:03:31.740464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-02 11:03:31.753510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-02 11:03:31.753843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-02 11:03:31.762748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-02 11:03:31.763830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-02 11:03:31.768414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 11:03:31.768579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:31.769543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:31.770282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-08-02 11:03:31.776375: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-08-02 11:03:31.776626: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x217ca00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 11:03:31.776662: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-02 11:03:31.831148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:31.831990: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x217cbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 11:03:31.832024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-08-02 11:03:31.832237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:31.832940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 11:03:31.833007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 11:03:31.833057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-02 11:03:31.833099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-02 11:03:31.833143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-02 11:03:31.833175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-02 11:03:31.833213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-02 11:03:31.833248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 11:03:31.833355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:31.834192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:31.834854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-08-02 11:03:31.834925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-02 11:03:31.836287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 11:03:31.836320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-08-02 11:03:31.836350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-08-02 11:03:31.836506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:31.837291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 11:03:31.837980: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-02 11:03:31.838061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv",
        "colab_type": "text"
      },
      "source": [
        "## Download the model `.tflite` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAqyASIJqjae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88dbb74b-80db-4d66-f32d-611373a02777"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "import os\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename('/content/object_detection_demo/hope_sih_v4.tflite')\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile('/content/object_detection_demo/hope_sih_v4.tflite')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "#fname = os.path.basename('/content/object_detection_demo/frozen_inference_graph.pb')\n",
        "#uploaded = drive.CreateFile({'title': fname})\n",
        "#uploaded.SetContentFile('/content/object_detection_demo/frozen_inference_graph.pb')\n",
        "#uploaded.Upload()\n",
        "#print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1_gbm7uP2zf9JB34PBDPZ218NM6Q1baLq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r270XdMYpypO",
        "colab_type": "text"
      },
      "source": [
        "# After this I downloaded object detection android example from official Tensorflow github repo and made following changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYJTinLIocr7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**1) Commented //apply from:download_model.gradle in gradle file.**\n",
        "\n",
        "**2) Added my_fruit.tflite file and labelmap.txt to assets folder.**\n",
        "\n",
        "**3) Gave paths to my tflite file and labelmap.txt in DetectorActivity.java**\n",
        "\n",
        "**4) Also set TF_OD_API_IS_QUANTIZED = false;**"
      ]
    }
  ]
}